{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":" Import packages and Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from surprise import Reader, Dataset, SVD, evaluate\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nr_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\nratings = pd.read_csv('../input/ml-100k/u.data', sep='\\t', names=r_cols, index_col='movie_id', encoding='latin-1')\n\nm_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url','unknown', 'Action', 'Adventure',\\\n          'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy','Film-Noir', 'Horror',\\\n          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\nmovies = pd.read_csv('../input/ml-100k/u.item', sep='|', names=m_cols, index_col=0, encoding='latin-1')\n\nu_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\nusers = pd.read_csv('../input/ml-100k/u.user', sep='|', names=u_cols, encoding='latin-1', parse_dates=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58fa71cb6410ffc6b2836568352abc7f958b595a"},"cell_type":"code","source":"from datetime import datetime\n\nratings['unix_timestamp'] = ratings['unix_timestamp'].apply(datetime.fromtimestamp)\nratings.columns = ['user_id', 'rating', 'time']\nratings.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a44105777459e2f32217f5cececf32e0b4147e1"},"cell_type":"markdown","source":"Here we can see how ratings distributed."},{"metadata":{"trusted":true,"_uuid":"2608e86389e9d294b25b28257372c8d936166053"},"cell_type":"code","source":"ratings['rating'].hist(bins=9)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35f0873b97f5b5be9ef1ddec9c19e7bc1d3f0736"},"cell_type":"markdown","source":"So far we will only use the movie title from this DataFrame. We may need the types of the movie later in our model."},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"25056ef96601e345d93521de6c4df7c256ddf9bb"},"cell_type":"code","source":"movies['release_date'] = pd.to_datetime(movies['release_date'])\nmovies.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7d6d4fa4157ba520c8c12c34047972354effe93"},"cell_type":"code","source":"for i in users['occupation'].unique():\n    users[i] = users['occupation'] == i\nusers.drop('occupation', axis=1, inplace=True)\nusers.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc7973ff9224380b2531282a88daffc826ed5b28"},"cell_type":"markdown","source":"For each movie we count how many ratings it got, and what's the mean and standard deviation."},{"metadata":{"trusted":true,"_uuid":"78bc2eab222460897f87d7ea31eec3f60559b323"},"cell_type":"code","source":"ratings_movie_summary = ratings.groupby('movie_id')['rating'].agg(['count', 'mean', 'std'])\nratings_movie_summary.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e81e333b15ebeb64077f684a2dd96ab6972450f"},"cell_type":"markdown","source":"For each user, we count how many ratings he or she gives, and the mean and standard deviation as well."},{"metadata":{"trusted":true,"_uuid":"b1401401de2fd15fbee4df92af8d352203ecf755"},"cell_type":"code","source":"ratings_user_summary = ratings.groupby('user_id')['rating'].agg(['count', 'mean', 'std'])\nratings_user_summary.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ecb4a322d23ff6f330bcb45f0e563998d847ba5"},"cell_type":"code","source":"ratings_movie_summary.sort_values(by='count')['count'].hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99c94bad715dfca5e04551870beeb471ca10a8f7"},"cell_type":"code","source":"ratings_movie_summary.sort_values(by='mean')['mean'].hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a29120842caa93367a5c7ecf4a00225cc5841c7c"},"cell_type":"code","source":"ratings_user_summary.sort_values(by='count')['count'].hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7cee3cf4cafcc5bbf21e4f542bb13e23f1189f2"},"cell_type":"code","source":"ratings_user_summary.sort_values(by='mean')['mean'].hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19fab17660ea6a24bac74092f78a8d6f753d373e"},"cell_type":"markdown","source":"We create a pivot table for ratings and store the total mean and standard deviation values."},{"metadata":{"trusted":true,"_uuid":"55c386a7c30ccd83393a2bb50cb1788930fc617f"},"cell_type":"code","source":"ratings_p = pd.pivot_table(ratings, values='rating', index='user_id', columns='movie_id')\nratings_p.iloc[:10, :10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68a4c1d875789a8713a61180a13c87e1f00eaf9d"},"cell_type":"code","source":"mean = ratings_p.stack().mean()\nstd = ratings_p.stack().std()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68de0e2c0d0793ad2e893c3f5afbf7101957ea3e"},"cell_type":"markdown","source":"**Notations:**\n\n$\\mu_i$ : The mean of all ratings received by movie i.\n\n$\\mu_u$ : The mean of all ratings from user u.\n\n$\\mu$ : The mean of all ratings.\n\n$\\sigma_i$ : The standard deviation of all ratings received by movie i.\n\n$\\sigma_u$ : The standard deviation of all ratings from user u.\n\n$r_{ui}$ : User u's rating on movie i.\n\n$\\hat{r}_{ui}$ : Prediction about user u's rating on movie i.\n\n$N^k_u(i)$ : k nearest neighbors of movie i, that are rated by user u."},{"metadata":{"_uuid":"5f75927ff57a3902f032157174cd1dafcedc1504"},"cell_type":"markdown","source":"- **Baseline Model**\n\nIn the first baseline model, we predict the rating from a specific user on a specific movie, just by the average rating that a movie receives, with adjustment by how this user's average rating compared with the total average.\n\n$$\\hat{r}_{ui} = \\mu_u + \\mu_i - \\mu$$"},{"metadata":{"trusted":true,"_uuid":"555f4f2a2995ff4ea9564dd1818a2b414b2354fe","_kg_hide-input":true},"cell_type":"code","source":"movie_mean = np.ones(ratings_p.shape)\nmovie_mean = pd.DataFrame(movie_mean * np.array(ratings_movie_summary['mean']).reshape(1,1682))\nuser_mean = np.ones(ratings_p.T.shape)\nuser_mean = pd.DataFrame(user_mean * np.array(ratings_user_summary['mean'])).T\npred = movie_mean + user_mean - mean\nscore = abs(np.array(ratings_p) - pred)\nscore_2 = score ** 2\nprint('RMSE: {:.4f}'.format(np.sqrt(score_2.stack().mean())))\nprint('MAE: {:.4f}'.format(score.stack().mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4532c9690508fe8835ec950533d98408b7ee6d08"},"cell_type":"markdown","source":"Since we don't have train-test-split in our prediction, we are actually using the mean of the data to predict every single data. Therefore, the score might be biased because of data leakage. So we do cross-validation on the model."},{"metadata":{"trusted":true,"_uuid":"dc9ffa108ba52ecec24d679d08995ae521fcdde4","_kg_hide-input":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nkfolds = KFold(n_splits = 5, random_state = 13)\nrmse = []\nmae = []\ni = 0\nprint('Evaluating RMSE, MAE of the Baseline Model. \\n')\nprint('-'*12)\nfor train_index, test_index in kfolds.split(ratings):\n    train = ratings.copy()\n    test = ratings.copy()\n    train['rating'].iloc[test_index] = np.NaN\n    test['rating'].iloc[train_index] = np.NaN\n    train_movie_summary = train.groupby('movie_id')['rating'].agg(['count', 'mean', 'std'])\n    train_user_summary = train.groupby('user_id')['rating'].agg(['count', 'mean', 'std'])\n    test_p = pd.pivot_table(test, values='rating', index='user_id', columns='movie_id', dropna=False)\n    movie_mean = np.ones(ratings_p.shape)\n    movie_mean = pd.DataFrame(movie_mean * np.array(train_movie_summary['mean']).reshape(1,1682))\n    user_mean = np.ones(ratings_p.T.shape)\n    user_mean = pd.DataFrame(user_mean * np.array(train_user_summary['mean'])).T\n    train_p = movie_mean + user_mean - mean\n    score = abs(np.array(test_p) - train_p)\n    score_2 = score ** 2\n    rmse += [np.sqrt(score_2.stack().mean())]\n    mae += [score.stack().mean()]\n    i += 1\n    print('Fold', i)\n    print('RMSE: {:.4f}'.format(np.sqrt(score_2.stack().mean())))\n    print('MAE: {:.4f}'.format(score.stack().mean()))\n    print('-'*12)\nprint('-'*12)\nprint('Mean RMSE: {:.4f}'.format(np.mean(rmse)))\nprint('Mean MAE: {:.4f}'.format(np.mean(mae)))\nprint('-'*12)\nprint('-'*12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02cf33de260ecbad8e2c74cc53de71347f0dff8f"},"cell_type":"markdown","source":"- **Baseline_Plus Model**\n\nIn the second model, we want to do it slightly better using z-score.\n\n$$\\hat{r}_{ui} = \\mu_u + \\sigma_u * \\frac{(\\mu_i - \\mu)}{\\sigma}$$"},{"metadata":{"trusted":true,"_uuid":"d457f3a000f5179331dde9a039fa6c0a0266fef7","_kg_hide-input":true},"cell_type":"code","source":"movie_mean = np.ones(ratings_p.shape)\nmovie_mean = pd.DataFrame(movie_mean * np.array(ratings_movie_summary['mean']).reshape(1,1682))\nuser_mean = np.ones(ratings_p.T.shape)\nuser_mean = pd.DataFrame(user_mean * np.array(ratings_user_summary['mean'])).T\nuser_std = np.ones(ratings_p.T.shape)\nuser_std = pd.DataFrame(user_std * np.array(ratings_user_summary['std'])).T\npred_plus = user_mean + (movie_mean - mean)/std * user_std\nscore_plus = abs(np.array(ratings_p) - pred_plus)\nscore_2_plus = score_plus ** 2\nprint('RMSE: {:.4f}'.format(np.sqrt(score_2_plus.stack().mean())))\nprint('MAE: {:.4f}'.format(score_plus.stack().mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca2b7cc5e4e54a340acc751cc478a92472b50899"},"cell_type":"markdown","source":"Use our baseline model to recommend movies for user 196."},{"metadata":{"trusted":true,"_uuid":"66c3370440df071c4628155c217ed62557679501"},"cell_type":"code","source":"user_196 = movies[['title', 'release_date']]\nuser_196['Estimate_Score'] = np.array(pred_plus.loc[195])\nuser_196 = user_196.sort_values('Estimate_Score', ascending=False)\nprint(user_196.head(10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bb3780138172bc8a9f1ce5a67542a573e7c4a95"},"cell_type":"markdown","source":"Here is the cross-validation score for our second model"},{"metadata":{"trusted":true,"_uuid":"f4d3ad826ab87cda2d1089509321612e03e1b8cf","_kg_hide-input":true},"cell_type":"code","source":"rmse_plus = []\nmae_plus = []\ni = 0\nprint('Evaluating RMSE, MAE of the Baseline_Plus Model. \\n')\nprint('-'*12)\nfor train_index, test_index in kfolds.split(ratings):\n    train = ratings.copy()\n    test = ratings.copy()\n    train['rating'].iloc[test_index] = np.NaN\n    test['rating'].iloc[train_index] = np.NaN\n    train_movie_summary = train.groupby('movie_id')['rating'].agg(['count', 'mean', 'std'])\n    train_user_summary = train.groupby('user_id')['rating'].agg(['count', 'mean', 'std'])\n    test_p = pd.pivot_table(test, values='rating', index='user_id', columns='movie_id', dropna=False)\n    movie_mean = np.ones(ratings_p.shape)\n    movie_mean = pd.DataFrame(movie_mean * np.array(train_movie_summary['mean']).reshape(1,1682))\n    user_mean = np.ones(ratings_p.T.shape)\n    user_mean = pd.DataFrame(user_mean * np.array(train_user_summary['mean'])).T\n    user_std = np.ones(ratings_p.T.shape)\n    user_std = pd.DataFrame(user_std * np.array(train_user_summary['std'])).T\n    train_p = user_mean + (movie_mean - mean)/std * user_std\n    score = abs(np.array(test_p) - train_p)\n    score_2 = score ** 2\n    rmse_plus += [np.sqrt(score_2.stack().mean())]\n    mae_plus += [score.stack().mean()]\n    i += 1\n    print('Fold', i)\n    print('RMSE: {:.4f}'.format(np.sqrt(score_2.stack().mean())))\n    print('MAE: {:.4f}'.format(score.stack().mean()))\n    print('-'*12)\nprint('-'*12)\nprint('Mean RMSE: {:.4f}'.format(np.mean(rmse_plus)))\nprint('Mean MAE: {:.4f}'.format(np.mean(mae_plus)))\nprint('-'*12)\nprint('-'*12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"521d9e989ba55700ed6f2f9a79b42bd65c86ffa7"},"cell_type":"markdown","source":"- **Baseline Model with SVM/Gradient Boosting**\n\nWe can improve this model even more, by applying SVM regressor or Gradient Boosting on each approximation, instead of just using z-score."},{"metadata":{"_uuid":"0c4d4443b8aff783f8ae9159bdd72251bef1c24c"},"cell_type":"markdown","source":"- SVM"},{"metadata":{"trusted":true,"_uuid":"22cf1986b95b4e955a48cc9b8ee4daaadc641f78","_kg_hide-input":true},"cell_type":"code","source":"from sklearn.svm import SVR\n\nmovie_mean = np.ones(ratings_p.shape)\nmovie_mean = pd.DataFrame(movie_mean * np.array(ratings_movie_summary['mean']).reshape(1,1682))\nX = np.array(ratings_p*0) + movie_mean\nsvm = SVR(gamma=1, C=1)\npred_svm = ratings_p.copy()\nfor i in range(ratings_p.shape[0]):\n    svm.fit(np.array(X.iloc[i].dropna()).reshape(-1,1), ratings_p.iloc[i].dropna())\n    pred_svm.iloc[i] = svm.predict(np.array(movie_mean.iloc[0]).reshape(-1,1))\nscore_svm = abs(np.array(ratings_p) - pred_svm)\nscore_2_svm = score_svm ** 2\nprint('RMSE: {:.4f}'.format(np.sqrt(score_2_svm.stack().mean())))\nprint('MAE: {:.4f}'.format(score_svm.stack().mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9702df20dd522c62f4be52082be443796f4af0f"},"cell_type":"markdown","source":"Use our svm model to recommend movies for user 196."},{"metadata":{"trusted":true,"_uuid":"c490b335433f0372a7488c7efe29e55e65a1ad59","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"user_196_svm = movies[['title', 'release_date']]\nuser_196_svm['Estimate_Score'] = np.array(pred_svm.loc[195])\nuser_196_svm = user_196_svm.sort_values('Estimate_Score', ascending=False)\nprint(user_196_svm.head(10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2613bcef37a68164ec5cda5a3464beafcc9bf69"},"cell_type":"markdown","source":"Cross-Validation"},{"metadata":{"trusted":true,"_uuid":"bbe414490d4e31f9ff1179a835e79ca79e692e73","_kg_hide-input":true},"cell_type":"code","source":"rmse_svm = []\nmae_svm = []\nfold = 0\nmovie_mean = pd.DataFrame(np.ones(ratings_p.shape) * np.array(ratings_movie_summary['mean']).reshape(1,1682))\nprint('Evaluating RMSE, MAE of the Baseline_SVM Model. \\n')\nprint('-'*12)\nfor train_index, test_index in kfolds.split(ratings):\n    train = ratings.copy()\n    test = ratings.copy()\n    train['rating'].iloc[test_index] = np.NaN\n    test['rating'].iloc[train_index] = np.NaN\n    train_movie_summary = train.groupby('movie_id')['rating'].agg(['count', 'mean', 'std'])\n    train_user_summary = train.groupby('user_id')['rating'].agg(['count', 'mean', 'std'])\n    train_p = pd.pivot_table(train, values='rating', index='user_id', columns='movie_id', dropna=False)\n    test_p = pd.pivot_table(test, values='rating', index='user_id', columns='movie_id', dropna=False)\n    train_mean = pd.DataFrame(np.ones(ratings_p.shape) * np.array(train_movie_summary['mean']).reshape(1,1682))\n    X = np.array(train_p*0) + train_mean\n    pred = ratings_p.copy()\n    for i in range(ratings_p.shape[0]):\n        svm.fit(np.array(X.iloc[i].dropna()).reshape(-1,1), train_p.iloc[i].dropna())\n        pred.iloc[i] = svm.predict(np.array(movie_mean.iloc[0]).reshape(-1,1))\n    score = abs(np.array(test_p) - pred)\n    score_2 = score ** 2\n    rmse_svm += [np.sqrt(score_2.stack().mean())]\n    mae_svm += [score.stack().mean()]\n    fold += 1\n    print('Fold', fold)\n    print('RMSE: {:.4f}'.format(np.sqrt(score_2.stack().mean())))\n    print('MAE: {:.4f}'.format(score.stack().mean()))\n    print('-'*12)\nprint('-'*12)\nprint('Mean RMSE: {:.4f}'.format(np.mean(rmse_svm)))\nprint('Mean MAE: {:.4f}'.format(np.mean(mae_svm)))\nprint('-'*12)\nprint('-'*12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fffee28226dd3bf147904d52e701bd12b0860da"},"cell_type":"markdown","source":"Gradient Boosting"},{"metadata":{"trusted":true,"_uuid":"8e226b62b89a6849998f48f1559436aa4541b028","_kg_hide-input":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n\nmovie_mean = np.ones(ratings_p.shape)\nmovie_mean = pd.DataFrame(movie_mean * np.array(ratings_movie_summary['mean']).reshape(1,1682))\nX = np.array(ratings_p*0) + movie_mean\nxgb = XGBRegressor(learning_rate=0.1, max_depth=2, min_child_weight=10, gamma=1)\npred_xgb = ratings_p.copy()\nfor i in range(ratings_p.shape[0]):\n    xgb.fit(np.array(X.iloc[i].dropna()).reshape(-1,1), ratings_p.iloc[i].dropna())\n    pred_xgb.iloc[i] = xgb.predict(np.array(movie_mean.iloc[0]).reshape(-1,1))\nscore_xgb = abs(np.array(ratings_p) - pred_xgb)\nscore_2_xgb = score_xgb ** 2\nprint('RMSE: {:.4f}'.format(np.sqrt(score_2_xgb.stack().mean())))\nprint('MAE: {:.4f}'.format(score_xgb.stack().mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"225df07b6670abc518be62f8d11a21b781308a54"},"cell_type":"markdown","source":"Cross-Validation"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"e8fbbe33f8b48cf8ffe78128bb72791e7a090a5f","_kg_hide-input":true},"cell_type":"code","source":"rmse_xgb = []\nmae_xgb = []\nfold = 0\nmovie_mean = pd.DataFrame(np.ones(ratings_p.shape) * np.array(ratings_movie_summary['mean']).reshape(1,1682))\nprint('Evaluating RMSE, MAE of the Baseline_XGB Model. \\n')\nprint('-'*12)\nfor train_index, test_index in kfolds.split(ratings):\n    train = ratings.copy()\n    test = ratings.copy()\n    train['rating'].iloc[test_index] = np.NaN\n    test['rating'].iloc[train_index] = np.NaN\n    train_movie_summary = train.groupby('movie_id')['rating'].agg(['count', 'mean', 'std'])\n    train_user_summary = train.groupby('user_id')['rating'].agg(['count', 'mean', 'std'])\n    train_p = pd.pivot_table(train, values='rating', index='user_id', columns='movie_id', dropna=False)\n    test_p = pd.pivot_table(test, values='rating', index='user_id', columns='movie_id', dropna=False)\n    train_mean = pd.DataFrame(np.ones(ratings_p.shape) * np.array(train_movie_summary['mean']).reshape(1,1682))\n    X = np.array(train_p*0) + train_mean\n    pred = ratings_p.copy()\n    for i in range(ratings_p.shape[0]):\n        xgb.fit(np.array(X.iloc[i].dropna()).reshape(-1,1), train_p.iloc[i].dropna())\n        pred.iloc[i] = xgb.predict(np.array(movie_mean.iloc[0]).reshape(-1,1))\n    score = abs(np.array(test_p) - pred)\n    score_2 = score ** 2\n    rmse_xgb += [np.sqrt(score_2.stack().mean())]\n    mae_xgb += [score.stack().mean()]\n    fold += 1\n    print('Fold', fold)\n    print('RMSE: {:.4f}'.format(np.sqrt(score_2.stack().mean())))\n    print('MAE: {:.4f}'.format(score.stack().mean()))\n    print('-'*12)\nprint('-'*12)\nprint('Mean RMSE: {:.4f}'.format(np.mean(rmse_xgb)))\nprint('Mean MAE: {:.4f}'.format(np.mean(mae_xgb)))\nprint('-'*12)\nprint('-'*12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b74e7553e1b18df4cbf9ccb4bba72d7cab31c5ee"},"cell_type":"markdown","source":"- **Pearsons'R Correlation Model**\n\nWe might also want to recommend movies just for a specific movie. Like the recommendation list showed on the webpage of a specific movie.\n\nHere we recommend new movies based on the Pearsons'R correlation between movies."},{"metadata":{"trusted":true,"_uuid":"1f817700d2330c4d010595d2faa94f05e8c5e522","_kg_hide-input":true},"cell_type":"code","source":"def recommend(movie_title, min_count):\n    print(\"For movie ({})\".format(movie_title))\n    print(\"- Top 10 movies recommended based on Pearsons'R correlation - \")\n    i = movies[movies['title'] == movie_title].index[0]\n    target = ratings_p[i]\n    similar_to_target = ratings_p.corrwith(target)\n    corr_target = pd.DataFrame(similar_to_target, columns = ['PearsonR'])\n    corr_target.dropna(inplace = True)\n    corr_target = corr_target.sort_values('PearsonR', ascending = False)\n    corr_target.index = corr_target.index.map(int)\n    corr_target = corr_target.join(movies).join(ratings_movie_summary)\\\n                  [['PearsonR', 'title', 'count', 'mean']]\n    print (corr_target[corr_target['count']>min_count][:10].to_string(index=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e54f02bb1f84169ce09a7593a38710a218270398"},"cell_type":"code","source":"recommend('Shawshank Redemption, The (1994)', 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bbf4d04e225a4daf640e212b244bac758f3f55c"},"cell_type":"markdown","source":"- **K-Nearest Neighbor (kNN) Model**\n\nWe can treat the **Pearsons' R Correlation** between movies as the distance, and using these distances to build a **K-Nearest Neighbor model**.\n\nNotations:\n\n$r_{ui}$ : User u's rating on movie i.\n\n$\\hat{r}_{ui}$ : Prediction about user u's rating on movie i.\n\n$N^k_u(i)$ : k nearest neighbors of movie i, that are rated by user u.\n\nThen we can have our kNN model as:\n\n$$\\hat{r}_{ui} = \\frac{\\sum_{j \\in N^k_u(i)} corr(i, j) * r_{uj}}{\\sum_{j \\in N^k_u(i)} corr(i, j)}$$"},{"metadata":{"trusted":true,"_uuid":"f5693cce65fc96899bcdf233004e1b84df913f1e"},"cell_type":"code","source":"sim = ratings_p.corr().abs()\nsim.iloc[:10, :10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"52ec496cef19fcaf951a76ae5aee525e8bf0fa4d","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"knn_pred = ratings_p.copy()\nfor i in ratings_p.index:\n    N = sim.loc[ratings[ratings['user_id'] == i].index]\n    for j in ratings_p.columns:\n        try:\n            N_k = N[j].sort_values(ascending=False).drop(j)[:30]\n        except:\n            N_k = N[j].sort_values(ascending=False)[:30]\n        weighted_rating = N_k*ratings_p.loc[i, N_k.index]\n        knn_pred.loc[i, j] = weighted_rating.sum()/N_k.sum()\n\nknn_pred.iloc[:10, :10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8772c4b4e1f93a47ea8a6e00c285b3c7cad7bd1","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"score_knn = abs(np.array(ratings_p) - knn_pred)\nscore_2_knn = score_knn ** 2\nprint('RMSE: {:.4f}'.format(np.sqrt(score_2_knn.stack().mean())))\nprint('MAE: {:.4f}'.format(score_knn.stack().mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c51f5035440cd944874342e763c9e433d2bf1acd"},"cell_type":"markdown","source":"train-test split score"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"62edec23de724d25c356e33d2a5cedb4fe1ef427"},"cell_type":"code","source":"train = ratings.copy()\ntest = ratings.copy()\ntrain['rating'].iloc[80000:] = np.NaN\ntest['rating'].iloc[:80000] = np.NaN\ntrain_movie_summary = train.groupby('movie_id')['rating'].agg(['count', 'mean', 'std'])\ntrain_user_summary = train.groupby('user_id')['rating'].agg(['count', 'mean', 'std'])\ntrain_p = pd.pivot_table(train, values='rating', index='user_id', columns='movie_id', dropna=False)\ntest_p = pd.pivot_table(test, values='rating', index='user_id', columns='movie_id', dropna=False)\n\nknn_pred = ratings_p.copy()\nfor i in ratings_p.index:\n    if i % 100 == 0:\n        print(i)\n    N = sim.loc[train[train['user_id'] == i].index]\n    for j in ratings_p.columns:\n        try:\n            N_k = N[j].sort_values(ascending=False).drop(j)[:30]\n        except:\n            N_k = N[j].sort_values(ascending=False)[:30]\n        weighted_rating = N_k*train_p.loc[i, N_k.index]\n        knn_pred.loc[i, j] = weighted_rating.sum()/N_k.sum()\n\nscore_knn = abs(np.array(ratings_p) - knn_pred)\nscore_2_knn = score_knn ** 2\nprint('RMSE: {:.4f}'.format(np.sqrt(score_2_knn.stack().mean())))\nprint('MAE: {:.4f}'.format(score_knn.stack().mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cbf11bf5c8b79c62b687e7570525145d372b39d"},"cell_type":"markdown","source":"- **kNN_Plus Model**\n\nNow we can improve our KNN model just by the same trick we used on our baseline model: adjust by the z-score.\n\nNotation:\n\n$\\mu_i$ : The mean of all ratings received by movie i.\n\n$\\sigma_i$ : The standard deviation of all ratings received by movie i.\n\n$$\\hat{r}_{ui} = \\mu_i + \\sigma_i * \\frac{\\sum_{j \\in N^k_u(i)} corr(i, j) *( r_{uj} - \\mu_j) / \\sigma_j}{\\sum_{j \\in N^k_u(i)} corr(i, j)}$$"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5b89ec701ee782ffac989d111365c1c6f1ee7f14","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"knn_plus_pred = ratings_p.copy()\nfor i in ratings_p.index:\n    N = sim.loc[ratings[ratings['user_id'] == i].index]\n    for j in ratings_p.columns:\n        try:\n            N_k = N[j].sort_values(ascending=False).drop(j)[:30]\n        except:\n            N_k = N[j].sort_values(ascending=False)[:30]\n        weighted_rating = N_k*(ratings_p.loc[i, N_k.index] - ratings_movie_summary.loc[N_k.index, 'mean'])/ ratings_movie_summary.loc[N_k.index, 'std']\n        knn_plus_pred.loc[i, j] = weighted_rating.sum()/N_k.sum() * ratings_movie_summary.loc[j, 'std'] + ratings_movie_summary.loc[j, 'mean']\n\nknn_plus_pred.iloc[:10, :10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a92121590e441f7763ed0a6c46546da158a0b3f8","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"score_knn_plus = abs(np.array(ratings_p) - knn_plus_pred)\nscore_2_knn_plus = score_knn ** 2\nprint('RMSE: {:.4f}'.format(np.sqrt(score_2_knn_plus.stack().mean())))\nprint('MAE: {:.4f}'.format(score_knn_plus.stack().mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87998a28d860627e779a44c5d88ec2ebb2c76984"},"cell_type":"markdown","source":"train-test split score."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ed37604b0b098dfb22756ab8cc4d2bbb563954d0"},"cell_type":"code","source":"train = ratings.copy()\ntest = ratings.copy()\ntrain['rating'].iloc[80001:] = np.NaN\ntest['rating'].iloc[:80001] = np.NaN\ntrain_movie_summary = train.groupby('movie_id')['rating'].agg(['count', 'mean', 'std'])\ntrain_user_summary = train.groupby('user_id')['rating'].agg(['count', 'mean', 'std'])\ntrain_p = pd.pivot_table(train, values='rating', index='user_id', columns='movie_id', dropna=False)\ntest_p = pd.pivot_table(test, values='rating', index='user_id', columns='movie_id', dropna=False)\n\nknn_plus_pred = ratings_p.copy()\nfor i in ratings_p.index:\n    if i % 100 == 0:\n        print(i)\n    N = sim.loc[train[train['user_id'] == i].index]\n    for j in ratings_p.columns:\n        try:\n            N_k = N[j].sort_values(ascending=False).drop(j)[:30]\n        except:\n            N_k = N[j].sort_values(ascending=False)[:30]\n        weighted_rating = N_k*(train_p.loc[i, N_k.index] - train_movie_summary.loc[N_k.index, 'mean'])/ train_movie_summary.loc[N_k.index, 'std']\n        knn_plus_pred.loc[i, j] = weighted_rating.sum()/N_k.sum() * train_movie_summary.loc[j, 'std'] + train_movie_summary.loc[j, 'mean']\n\nscore_knn = abs(np.array(ratings_p) - knn_plus_pred)\nscore_2_knn = score_knn ** 2\nprint('RMSE: {:.4f}'.format(np.sqrt(score_2_knn.stack().mean())))\nprint('MAE: {:.4f}'.format(score_knn.stack().mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be4f0a3236e2fbfa2224be5261c900f87ad10c60"},"cell_type":"markdown","source":"- **Supervised Learning Model**\n\nGradient Boosting as supervised learning.\n\nI take each user-movie combination as one instance, and hence take full use of the features from the user and movie."},{"metadata":{"trusted":true,"_uuid":"c4fa949605f173a8a6e8718afe68ace1e03e2390","_kg_hide-input":true},"cell_type":"code","source":"from datetime import datetime\n\nr_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\nratings = pd.read_csv('../input/ml-100k/u.data', sep='\\t', names=r_cols, encoding='latin-1')\nratings['unix_timestamp'] = ratings['unix_timestamp'].apply(datetime.fromtimestamp)\nratings.columns = ['user_id', 'movie_id', 'rating', 'time']\nratings.head(10)\n\nm_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url','unknown', 'Action', 'Adventure',\\\n          'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy','Film-Noir', 'Horror',\\\n          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\nmovies = pd.read_csv('../input/ml-100k/u.item', sep='|', names=m_cols, encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c3414c35a1213da5e54e6a5dd4e846da69f793f","_kg_hide-input":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\n#occupation = {'none': 0, 'administrator': 1, 'artist': 2, 'doctor': 3, 'educator': 4, 'engineer': 5, 'entertainment': 6,\\\n#              'executive': 7, 'healthcare': 8, 'homemaker': 9, 'lawyer': 10, 'librarian': 11, 'marketing': 12,\\\n#              'programmer': 13, 'salesman': 14, 'scientist': 15, 'student': 16, 'technician': 17, 'writer': 18,\\\n#              'retired': 19, 'other': 20}\ndf = ratings_p.stack(dropna=False).reset_index()\ndf.columns = ['user_id', 'movie_id', 'rating']\ndf = df.merge(users, on='user_id')\ndf = df.merge(movies, on='movie_id')\ndf['sex'] = df['sex'].replace(['F', 'M'], [1, 0])\n#df['occupation'] = df['occupation'].replace(occupation)\ndf.drop(['release_date', 'video_release_date', 'imdb_url', 'title', 'zip_code'], axis=1, inplace=True)\ndf_train = df.dropna()\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"158054a7a22cec94467297f867e6da47b311e7c8","_kg_hide-input":true},"cell_type":"code","source":"rmse_reg = []\nmae_reg = []\ni = 0\nprint('Evaluating RMSE, MAE of the XGB_Reg Model. \\n')\nprint('-'*12)\nfor train_index, test_index in kfolds.split(ratings):\n    X_train = df_train.drop('rating', axis=1).iloc[train_index]\n    y_train = df_train['rating'].iloc[train_index]\n    X_test = df_train.drop('rating', axis=1).iloc[test_index]\n    y_test = df_train['rating'].iloc[test_index]\n    xgb = XGBRegressor(learning_rate=0.1, max_depth=10, min_child_weight=10, gamma=0.03).fit(X_train, y_train)\n    y_pred = xgb.predict(X_test)\n    score = abs(y_test - y_pred)\n    score_2 = score**2\n    rmse_reg += [np.sqrt(np.mean(score_2))]\n    mae_reg += [np.mean(score)]\n    i += 1\n    print('Fold', i)\n    print('RMSE: {:.4f}'.format(np.sqrt(np.mean(score_2))))\n    print('MAE: {:.4f}'.format(np.mean(score)))\n    print('-'*12)\nprint('-'*12)\nprint('Mean RMSE: {:.4f}'.format(np.mean(rmse_reg)))\nprint('Mean MAE: {:.4f}'.format(np.mean(mae_reg)))\nprint('-'*12)\nprint('-'*12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45f5343289f9a6f654909f9dc1af68a06a1d69aa"},"cell_type":"markdown","source":"The next model takes more than 6 hours to run. So I don't commit it this time. I'll move it into a seperate notebook."},{"metadata":{"_uuid":"1a49d2277c92a93f1dd5802e257f0bcbd1cd3e32"},"cell_type":"markdown","source":"- **Improvement on Gradient Boosting Model (?)**\n\nIn the previous model, we use rating as the target variable, therefore the model knows nothing about what ratings that the movie has received, and what ratings the user has given. Now we might want to include all related ratings, both from the same user and for the same movie, as features in our model.\n\nThis model takes a much longer time than others.\n\nNotice that two of the slots on each row in these new features will actually contain the target value! However, I right now have no clue that this will result in data leakage since the model has no idea where these hidden correct ratings locate.\n\nIt makes sense that this model will beat all other models, since it contains more information like the age and gender of the user, genre of the movie, etc. However, it is still not safe to say that we are free of data leakage here. So I leave a question mark here."},{"metadata":{"trusted":true,"_uuid":"ee84bb76091248cf663fd0e48c797731d1900374","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"### BUG. Need Fix. ###\n\n#df = df.merge(ratings_p, left_on='user_id', right_index=True)\n#df = df.merge(ratings_p.T, left_on='movie_id', right_index=True)\n#df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39d9b2fbd5358f998071bac8f8de5c2e45bbe3b0","_kg_hide-input":true},"cell_type":"code","source":"#df_train = df_train.merge(ratings_p, left_on='user_id', right_index=True)\n#df_train = df_train.merge(ratings_p.T, left_on='movie_id', right_index=True)\n#df_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"252b024fb228156923f286f3b57b39188093bfdb","_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"#for i in range(df_train.shape[0]):\n#    if i % 1000 == 0:\n#        print(i)\n#    row = df_train.iloc[i]\n#    df_train.iloc[i][str(row[1])+'_x'] = np.NaN\n#    df_train.iloc[i][str(row[0])+'_y'] = np.NaN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a57004d0967b668ccbb18e9b708736ddb3661464"},"cell_type":"markdown","source":"Train-test-split score."},{"metadata":{"trusted":true,"_uuid":"70431be331057c500c244d88dede926cdbdeee6e","_kg_hide-input":true},"cell_type":"code","source":"#X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['rating'], axis=1), df_train['rating'], random_state = 0)\n#xgb = XGBRegressor(learning_rate=0.1, max_depth=10, min_child_weight=10, gamma=0.03).fit(X_train, y_train)\n#y_pred = xgb.predict(X_test)\n#score = abs(y_test - y_pred)\n#score_2 = score**2\n#print('RMSE: {:.4f}'.format(np.sqrt(np.mean(score_2))))\n#print('MAE: {:.4f}'.format(np.mean(score)))\n\n# RMSE: 0.7401\n# MAE: 0.5674","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bafe0d310b37624a9be8b65198bc8277dd67b8cf"},"cell_type":"markdown","source":"Use our model to recommond movie for user 196."},{"metadata":{"_uuid":"74e6fe1c42fbfae88b3742da2a49e4bd9b038dd0"},"cell_type":"markdown","source":"Here is all movies rated by user 196."},{"metadata":{"trusted":true,"_uuid":"d2ea8d95232358b905f58f29ca7c4a6453ae1b0a"},"cell_type":"code","source":"#pred_196 = df[df['user_id']==196]\n#pred_196 = pred_196.merge(ratings_p, left_on='user_id', right_index=True)\n#pred_196 = pred_196.merge(ratings_p.T, left_on='movie_id', right_index=True)\n#pred_196.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"937d2a427b5f6719c2c6c3a77321f3b857fdb183"},"cell_type":"markdown","source":"Here is the recommendation to user 196."},{"metadata":{"trusted":true,"_uuid":"b70b286d73e8500582da543585f322e0d185774c","_kg_hide-input":true},"cell_type":"code","source":"#xgb = XGBRegressor(learning_rate=0.1, max_depth=10, min_child_weight=10, gamma=0.03)\\\n#      .fit(df_train.drop(['rating'], axis=1), df_train['rating'])\n#pred_196['rating'] = xgb.predict(pred_196.drop('rating', axis=1))\n#user_196_reg = movies[['movie_id', 'title', 'release_date']]\n#user_196_reg['Estimate_Score'] = np.array(pred_196['rating'])\n#user_196_reg.drop('movie_id', axis=1, inplace=True)\n#user_196_reg = user_196_reg.sort_values('Estimate_Score', ascending=False)\n#print(user_196_reg.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d72a08f0b96a6701946532c780ca4449410c1a2c"},"cell_type":"markdown","source":"Cross-Validation"},{"metadata":{"trusted":true,"_uuid":"4857096d99a1021818206e0ecfa7a3b0458d70ea","_kg_hide-input":true},"cell_type":"code","source":"#rmse_reg_plus = []\n#mae_reg_plus = []\n#i = 0\n#print('Evaluating RMSE, MAE of the XGB_Reg_Plus Model. \\n')\n#print('-'*12)\n#for train_index, test_index in kfolds.split(ratings):\n#    X_train = df_train.drop('rating', axis=1).iloc[train_index]\n#    y_train = df_train['rating'].iloc[train_index]\n#    X_test = df_train.drop('rating', axis=1).iloc[test_index]\n#    y_test = df_train['rating'].iloc[test_index]\n#    xgb = XGBRegressor(learning_rate=0.1, max_depth=10, min_child_weight=10, gamma=0.03).fit(X_train, y_train)\n#    y_pred = xgb.predict(X_test)\n#    score = abs(y_test - y_pred)\n#    score_2 = score**2\n#    rmse_reg_plus += [np.sqrt(np.mean(score_2))]\n#    mae_reg_plus += [np.mean(score)]\n#    i += 1\n#    print('Fold', i)\n#    print('RMSE: {:.4f}'.format(np.sqrt(np.mean(score_2))))\n#    print('MAE: {:.4f}'.format(np.mean(score)))\n#    print('-'*12)\n#print('-'*12)\n#print('Mean RMSE: {:.4f}'.format(np.mean(rmse_reg_plus)))\n#print('Mean MAE: {:.4f}'.format(np.mean(mae_reg_plus)))\n#print('-'*12)\n#print('-'*12)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}